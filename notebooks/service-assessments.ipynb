{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d591a33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import pymongo\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import pathlib\n",
    "pd.set_option(\"max_colwidth\", 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb8ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some useful mappings\n",
    "# Actually not that useful, as some reports reference 'point 26', which afaik doesnt exist\n",
    "\n",
    "july_2019_id_to_crit = {\n",
    "    1: 'understand user needs',\n",
    "    2: 'do ongoing user research',\n",
    "    3: 'have a multidisciplinary team',\n",
    "    4: \"use agile methods\",\n",
    "    5: \"Iterate and improve frequently\",\n",
    "    6: \"Evaluate tools and systems\",\n",
    "    7: \"Understand security and privacy issues\",\n",
    "    8: \"Make all new source code open\",\n",
    "    9: \"Use open standards and common platforms\",\n",
    "    10: \"Test the end-to-end service\",\n",
    "    11: \"Make a plan for being offline\",\n",
    "    12: \"Make sure users succeed first time\",\n",
    "    13: \"Make the user experience consistent with GOV.UK\",\n",
    "    14: \"Encourage everyone to use the digital service\",\n",
    "    15: \"Collect performance data\",\n",
    "    16: \"Identify performance indicators\",\n",
    "    17: \"Report performance data on the Performance Platform\",\n",
    "    18: \"Test with the minister\"\n",
    "}\n",
    "july_2019_id_to_crit = {key: value.lower().replace(' ', '-') for key, value in july_2019_id_to_crit.items()}\n",
    "july_2019_crit_to_id = {value: key for key, value in july_2019_id_to_crit.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500c93b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_crit = {\n",
    "    1: \"Understand users and their needs\",\n",
    "    2: \"Solve a whole problem for users\",\n",
    "    3: \"Provide a joined up experience across all channels\",\n",
    "    4: \"Make the service simple to use\",\n",
    "    5: \"Make sure everyone can use the service\",\n",
    "    6: \"Have a multidisciplinary team\",\n",
    "    7: \"Use agile ways of working\",\n",
    "    8: \"Iterate and improve frequently\",\n",
    "    9: \"Create a secure service which protects usersâ€™ privacy\",\n",
    "    10: \"Define what success looks like and publish performance data\",\n",
    "    11: \"Choose the right tools and technology\",\n",
    "    12: \"Make new source code open\",\n",
    "    13: \"Use and contribute to open standards, common components and patterns\",\n",
    "    14: \"Operate a reliable service\"\n",
    "}\n",
    "id_to_crit = {key: value.lower().replace(' ','-') for key, value in current_crit.items()}\n",
    "crit_to_id = {value: key for key, value in id_to_crit.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7fe818",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Service assessment content pages\n",
    "urls = ['https://www.gov.uk/service-standard-reports?page=1',\n",
    "       'https://www.gov.uk/service-standard-reports?page=2',\n",
    "       'https://www.gov.uk/service-standard-reports?page=3',\n",
    "       'https://www.gov.uk/service-standard-reports?page=4',\n",
    "       'https://www.gov.uk/service-standard-reports?page=5']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09c09687",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_assessment_path_and_metadata(urllist):\n",
    "    \"\"\"\n",
    "    Scrape meta data from each page of\n",
    "    https://www.gov.uk/service-standard-reports\n",
    "    Should be 225 reports\n",
    "    \"\"\"\n",
    "    assessments_dict= {}\n",
    "    for url in urllist:\n",
    "        page = requests.get(url)\n",
    "        html = BeautifulSoup(page.content, 'html.parser')\n",
    "        items = html.find_all(\"li\", class_=\"gem-c-document-list__item\")\n",
    "        links = [item.find('a').get('href') for item in items]\n",
    "        assessments = [item.find_all('li', class_=\"gem-c-document-list__attribute\") for item in items]\n",
    "        for index,item in enumerate(assessments):\n",
    "            texts = [re.sub(r'[^\\w\\s]','',thing.text).lower().strip('\\n').strip(' ').split(\" \",1) for thing in item]\n",
    "            record = {}\n",
    "            for value in texts:\n",
    "                record[value[0]] = value[1]\n",
    "            assessments_dict[links[index]] = record\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(assessments_dict,'index').reset_index()\n",
    "    df.columns = ['path','assessment_outcome','stage','assessment_date']\n",
    "    df['url'] = 'https://www.gov.uk' + df['path']\n",
    "    df['api_path'] = 'https://www.gov.uk/api/content' + df['path']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a71d619",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_assessment_path_and_metadata(urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(df.shape[0] == 224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bdbeb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix just one missing assessment date\n",
    "print(df[df['assessment_date'].isna()])\n",
    "df.iloc[75]['assessment_date'] = '12 September 2019'\n",
    "df['assessment_date'] = df['assessment_date'].map(\n",
    "    lambda x: datetime.datetime.strptime(x,\"%d %B %Y\").date())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b372241",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tests meta data scraping\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/file-your-confirmation-statement-alpha-assessment-report'][[\n",
    "    'assessment_outcome', 'stage','assessment_date'\n",
    "]].values[0].tolist() == ['met','alpha',datetime.datetime.strptime('2021-3-23',\"%Y-%m-%d\").date()]\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/nhs-111'][[\n",
    "    'assessment_outcome', 'stage','assessment_date'\n",
    "]].values[0].tolist() == ['met','alpha',datetime.datetime.strptime('2016-4-28',\"%Y-%m-%d\").date()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015845e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_assessment_outcome_from_para(url):\n",
    "    \"\"\"\n",
    "    Scrapes outcome from paragraph as per \n",
    "    https://www.gov.uk/service-standard-reports/check-your-state-pension-beta-assessment\n",
    "    \n",
    "    Args:\n",
    "        url (string): url for scraping \n",
    "\n",
    "    Returns:\n",
    "        string: a string (hopefully) indicating pass/fail\n",
    "    \"\"\"\n",
    "    request = requests.get(url)\n",
    "    page = BeautifulSoup(request.content)\n",
    "    paras = page.find_all(\"strong\")\n",
    "    paras = np.array([para.parent.text.lower() for para in paras])\n",
    "    text = ([bool(re.search('result',para)) for para in paras])\n",
    "    results = paras[text]\n",
    "    try:\n",
    "        result = [result.rsplit('\\n')[1] for result in results]\n",
    "        result\n",
    "    except IndexError:\n",
    "        result = None\n",
    "    # Occasionally we get two results, for prior assessments, we just want the most recent one\n",
    "    result = result[len(result)-1] if result else None\n",
    "    return result\n",
    "\n",
    "def scrape_summary_table(url):\n",
    "    \"\"\"\n",
    "    Scrapes meta from table on page as per\n",
    "    https://www.gov.uk/service-standard-reports/apply-for-a-blue-badge-beta-assessment\n",
    "    \n",
    "    Args:\n",
    "        url (string): url for scraping \n",
    "\n",
    "    Returns:\n",
    "        summary_table (dict): dictionary with table column1 as keys and table column2 as values\n",
    "    \n",
    "    \"\"\"\n",
    "    request = requests.get(url)\n",
    "    page = BeautifulSoup(request.content)\n",
    "    trs = page.find_all(\"tr\")\n",
    "    lines = [re.sub(r'[^\\w\\s]','',tr.text).lower().strip('\\n').split('\\n') for tr in trs]\n",
    "    key = [x[0] for x in lines]\n",
    "    value = [x[1] for x in lines]\n",
    "    summary_table = dict(zip(key,value))\n",
    "\n",
    "    return summary_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca893a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get missing pass/fails from scraping paras\n",
    "df['scraped_result'] = df['url'].map(scrape_assessment_outcome_from_para)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a108db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scrape assessment outcome from para\n",
    "assert df[df['path']=='/service-standard-reports/check-your-state-pension-beta-assessment'][[\n",
    "    'scraped_result'\n",
    "]].values[0].tolist() == ['pass']\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/redundancy-payments-alpha-assessment'][[\n",
    "    'scraped_result'\n",
    "]].values[0].tolist() == ['met']\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/civil-service-learning-course-booking-alpha-assessment'][[\n",
    "    'scraped_result'\n",
    "]].values[0].tolist() == ['not pass']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ef7d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca6d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get missing meta data from summary table\n",
    "df['summary_table'] = df['url'].map(scrape_summary_table)\n",
    "df['st_result'] = df['summary_table'].map(lambda x: x.get('result'))\n",
    "df['st_stage'] = df['summary_table'].map(lambda x: x.get('stage'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd1f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test scrape assessment outcome from table\n",
    "assert df[df['path']=='/service-standard-reports/apply-for-a-blue-badge-beta-assessment'][[\n",
    "    'st_result',\n",
    "    'st_stage'\n",
    "]].values[0].tolist() == ['met','beta']\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/electronic-data-collection-alpha-assessment'][[\n",
    "    'st_result',\n",
    "    'st_stage'\n",
    "]].values[0].tolist() == ['met','alpha']\n",
    "\n",
    "assert df[df['path']=='/service-standard-reports/driving-theory-test-booking-alpha'][[\n",
    "    'st_result',\n",
    "    'st_stage',\n",
    "]].values[0].tolist() == ['not met','alpha']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7d7c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce our API, scraped p and scraped table outcomes/stages\n",
    "# Priority is API > Summary table > p\n",
    "df['stage'] =df['stage'].combine_first(df['st_stage'])\n",
    "df['assessment_outcome'] = df['assessment_outcome'].combine_first(df['scraped_result'])\n",
    "df['assessment_outcome'] = df['assessment_outcome'].combine_first(df['st_result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91eb17b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Outcome description\n",
    "df.groupby('assessment_outcome',dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f8bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map outcome/stage strings to proper thing\n",
    "stage_map = {\n",
    "'alpha': 'alpha',\n",
    "'alpha  reassessment':'alpha-reassessment',\n",
    "'alpha reassessment' : 'alpha-reassessment',\n",
    "'alpha2' : 'alpha',\n",
    "'alphareassessment':'alpha-reassessment',\n",
    "'beta': 'beta',\n",
    "'beta reassessment':'beta-reassessment', \n",
    "'beta2': 'beta',\n",
    "'betareassessment': 'beta-reassessment',\n",
    "'live':'live',                \n",
    "'live2':'live'       \n",
    "}\n",
    "\n",
    "outcome_map = {\n",
    "'met' : 'met',                     \n",
    "'not met' : 'not-met',                  \n",
    "'not pass' : 'not-met',                 \n",
    "'notmet' : 'not-met',                   \n",
    "'pass' : 'met',                     \n",
    "'pass with conditions': 'met',      \n",
    "'passed' : 'met',      \n",
    "'not-met': 'not-met',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ce9d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map variously phrased outcomes and stages to an outcome or stage\n",
    "df['stage'] = df['stage'].map(lambda x: stage_map.get(x))\n",
    "df['assessment_outcome'] = df['assessment_outcome'].map(lambda x: outcome_map.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44fae00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('assessment_outcome',dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f7d005",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('stage',dropna=False).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92797a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_met_standard_id_in_p(url):\n",
    "    \"\"\"\n",
    "    Extract line containing standard id and status from <p> elements\n",
    "    \"\"\"\n",
    "    request = requests.get(url)\n",
    "    page = BeautifulSoup(request.content)\n",
    "    paras = page.find_all(\"p\")\n",
    "    crit = []\n",
    "    for para in paras:\n",
    "        if re.search('point \\d+', str(para)):\n",
    "            crit.append(para.text)\n",
    "    return crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60379e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['criteria-id-from-p'] = df['url'].map(find_met_standard_id_in_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8469a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_id_and_status(lines):\n",
    "    \"\"\"\n",
    "    Extract id and status from raw text string\n",
    "    \"\"\"\n",
    "    data = {'met':[],'not-met':[]}\n",
    "    criteria = [int(re.search('\\d+',line).group()) for line in lines]\n",
    "    status = ['not-met' if re.search('not',line) else 'met' for line in lines]\n",
    "    [data[x].append(criteria[idx]) for idx,x in enumerate(status)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f81efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['criteria'] = df['criteria-id-from-p'].map(extract_id_and_status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a83b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unnest criteria dict\n",
    "df['met-criteria-from-p'] = df['criteria'].map(lambda x: x.get('met'))\n",
    "df['unmet-criteria-from-p'] = df['criteria'].map(lambda x: x.get('not-met'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023b81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test extract id and status from p\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/file-your-confirmation-statement-alpha-assessment-report'][[\n",
    "    'met-criteria-from-p',\n",
    "    'unmet-criteria-from-p'\n",
    "]].values[0].tolist() == [[1,2,3,4,5,6,7,8,9,10,11,12,13,14],[]]\n",
    "\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/apply-for-a-deceased-persons-military-record-request-a-service-record-beta-reassessment-report'][[\n",
    "    'met-criteria-from-p',\n",
    "    'unmet-criteria-from-p'\n",
    "]].values[0].tolist() == [[10,13],[]]\n",
    "\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/request-a-service-record-beta-reassessment-report'][[\n",
    "    'met-criteria-from-p',\n",
    "    'unmet-criteria-from-p'\n",
    "]].values[0].tolist() == [[3,7,11,14,15,16],[10,13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860222f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_met_criteria_in_table(url):\n",
    "    \"\"\"\n",
    "    Extracts individual criteria and outcome from two types of table:\n",
    "    3 column table as per https://www.gov.uk/service-standard-reports/new-secure-access-alpha-reassessment\n",
    "    4 column table as per https://www.gov.uk/service-standard-reports/claim-for-crown-court-defence\n",
    "    \"\"\"\n",
    "    request = requests.get(url)\n",
    "    page = BeautifulSoup(request.content)\n",
    "    trs = page.find_all(\"tr\")\n",
    "    met_criteria_from_table = []\n",
    "    unmet_criteria_from_table = []\n",
    "    for x,tr in enumerate(trs):\n",
    "        # 3 column table\n",
    "        tds = tr.find_all('td')\n",
    "        if len(tds) ==3:    \n",
    "            for y,td in enumerate(tds):\n",
    "                if td.string:\n",
    "                    try:\n",
    "                        point_id = int(td.string)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    #ignore points we have no data for\n",
    "                    if point_id <= 18:\n",
    "                        if tds[y+2].string.lower() == 'met':\n",
    "                            met_criteria_from_table.append(point_id)\n",
    "                        elif tds[y+2].string.lower() == 'not met':\n",
    "                            unmet_criteria_from_table.append(point_id)\n",
    "        # 4 column table \n",
    "        elif len(tds)==4:\n",
    "            for y,td in enumerate(tds):\n",
    "                if td.string:\n",
    "                    try:\n",
    "                        point_id = int(td.string)\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "                    #ignore points we have no data for\n",
    "                    if point_id <= 18:\n",
    "                        if tds[y+1].string.lower() == 'yes':\n",
    "                            met_criteria_from_table.append(point_id)\n",
    "                        elif tds[y+1].string.lower() == 'no':\n",
    "                            unmet_criteria_from_table.append(point_id)\n",
    "    return {'met': met_criteria_from_table, 'unmet':unmet_criteria_from_table}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371aaf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['criteria_from_table'] = df['url'].map(lambda x: find_met_criteria_in_table(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c993163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unnest table criteria dicts\n",
    "df['met-criteria-from-table'] = df['criteria_from_table'].map(lambda x: x.get('met'))\n",
    "df['unmet-criteria-from-table'] = df['criteria_from_table'].map(lambda x: x.get('unmet'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59901f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coalesce data scraped from table and from p\n",
    "# Table is more reliable than p\n",
    "df['met-criteria-from-table'] = df['met-criteria-from-table'].map(lambda x: np.nan if len(x)==0 else x)\n",
    "df['unmet-criteria-from-table'] = df['unmet-criteria-from-table'].map(lambda x: np.nan if len(x)==0 else x)\n",
    "df['all-met-criteria'] = df['met-criteria-from-table'].combine_first(df['met-criteria-from-p'])\n",
    "df['met'] = df['all-met-criteria'].map(lambda x: list(set(map(int,x))))\n",
    "df['all-unmet-criteria'] = df['unmet-criteria-from-table'].combine_first(df['unmet-criteria-from-p'])\n",
    "df['not-met'] = df['all-unmet-criteria'].map(lambda x: list(set(map(int,x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523fbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the criteria breakdown extraction\n",
    "#Test extract id and status from p\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/apprenticeship-applications'][[\n",
    "    'met',\n",
    "    'not-met'\n",
    "]].values[0].tolist() == [[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17],[]]\n",
    "\n",
    "\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/close-a-company-beta-service-assessment-report'][[\n",
    "    'met',\n",
    "    'not-met'\n",
    "]].values[0].tolist() == [[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,17,18],[16]]\n",
    "\n",
    "assert df[df['url']=='https://www.gov.uk/service-standard-reports/express-an-interest-in-a-repatriation-flight-alpha-assessment-report'][[\n",
    "    'met',\n",
    "    'not-met'\n",
    "]].values[0].tolist() == [[11,13,7],[1,2,3,4,5,6,8,9,10,12,14]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b76cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map IDs to service standard as best we can\n",
    "cutoff = datetime.datetime.strptime('2019-06-30', '%Y-%m-%d' ).date()\n",
    "df['current_service_standard'] = df.apply(lambda x:\n",
    "    (x['assessment_date']>cutoff ) & (max(set(x['all-met-criteria']).union(set(x['all-unmet-criteria'])),default=1)<15),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c6d347",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72eb0b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tidy for export\n",
    "export = df[['path',\n",
    "             'assessment_outcome',\n",
    "             'stage',\n",
    "             'assessment_date',\n",
    "             'current_service_standard',\n",
    "             'met',\n",
    "             'not-met']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef4c8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = export.melt(id_vars=['path','assessment_outcome','stage','assessment_date','current_service_standard'],\n",
    "           var_name='status',value_name='assessment_criteria_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4c2e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "export = export.explode('assessment_criteria_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fdb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aceb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "def criteria_to_id_mapper(criteria, current_service_standard):\n",
    "    \"\"\"\n",
    "    Maps id to 'correct' service standard\n",
    "    \"\"\"\n",
    "    if current_service_standard==True:\n",
    "        crit_codes = id_to_crit.get(criteria)\n",
    "    else:\n",
    "        crit_codes = july_2019_id_to_crit.get(criteria)\n",
    "    return crit_codes  \n",
    "\n",
    "export['criteria-desc'] = export.apply(\n",
    "    lambda x: criteria_to_id_mapper(x['assessment_criteria_id'],x['assessment_date']),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87240841",
   "metadata": {},
   "outputs": [],
   "source": [
    "export['path'] = export['path'].map(lambda x: x.rsplit('/',1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6deec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b20162",
   "metadata": {},
   "outputs": [],
   "source": [
    "export.to_csv('assessment_crit_breakdown.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ebb6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = export[['path','assessment_outcome','stage','assessment_date']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211bdf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.shape[0] == 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89f6f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary.to_csv('service-assessment-summary.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "language": "python",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
